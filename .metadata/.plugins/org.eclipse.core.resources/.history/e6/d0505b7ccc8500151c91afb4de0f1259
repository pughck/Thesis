package edu.rosehulman.pughck;

import java.io.IOException;
import java.util.Map;
import java.util.Timer;
import java.util.TimerTask;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.Path;
import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;

import backtype.storm.task.OutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichBolt;
import backtype.storm.tuple.Tuple;

@SuppressWarnings("serial")
public class MyHdfsBolt extends BaseRichBolt {

	private final String basePath = "/tmp/stormOutput/";
	private OutputCollector collector;

	@Override
	public void execute(Tuple tuple) {

		try {
			String comp = tuple.getStringByField("company");
			long time = System.currentTimeMillis() / 60000; // to minutes
			Path path = new Path(this.basePath + comp + "/", time + ".txt");
			FSDataOutputStream out = null;

			byte[] bytes = tuple.getStringByField("tweet").getBytes();

			this.out = this.fs.create(path);

			out.write(bytes);

			this.collector.ack(tuple);
		} catch (IOException e) {
			this.collector.fail(tuple);
		}
	}

	@SuppressWarnings("rawtypes")
	@Override
	public void prepare(Map map, TopologyContext context, OutputCollector collector) {

		this.collector = collector;
	}

	@Override
	public void declareOutputFields(OutputFieldsDeclarer declarer) {

	}
}
