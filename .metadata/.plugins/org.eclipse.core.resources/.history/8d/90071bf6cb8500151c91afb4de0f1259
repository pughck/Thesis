package edu.rosehulman.pughck;

import java.io.IOException;
import java.util.Map;
import java.util.Timer;
import java.util.TimerTask;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.storm.hdfs.common.security.HdfsSecurityUtil;

import backtype.storm.task.OutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichBolt;
import backtype.storm.tuple.Tuple;

@SuppressWarnings("serial")
public class MyHdfsBolt extends BaseRichBolt {

	private OutputCollector collector;

	@Override
	public void execute(Tuple tuple) {

		try {
			String comp = tuple.getStringByField("company");
			long time = System.currentTimeMillis();

			System.out.println(comp);

			Path path = new Path(this.fileNameFormat.getPath() + comp + "/", time + ".txt");

			System.out.println(path);

			byte[] bytes = this.format.format(tuple);

			// synchronized (this.writeLock) {

			this.out = this.fs.create(path);

			out.write(bytes);
			// this.offset += bytes.length;
			//
			// if (this.syncPolicy.mark(tuple, this.offset)) {
			// if (this.out instanceof HdfsDataOutputStream) {
			// ((HdfsDataOutputStream)
			// this.out).hsync(EnumSet.of(SyncFlag.UPDATE_LENGTH));
			// } else {
			// this.out.hsync();
			// }
			// this.syncPolicy.reset();
			// }
			// }

			this.collector.ack(tuple);

			// if (this.rotationPolicy.mark(tuple, this.offset)) {
			// rotateOutputFile(); // synchronized
			// this.offset = 0;
			// this.rotationPolicy.reset();
			// }
		} catch (IOException e) {
			this.collector.fail(tuple);
		}
	}

	@SuppressWarnings("rawtypes")
	@Override
	public void prepare(Map map, TopologyContext context, OutputCollector collector) {

		this.collector = collector;
	}

	@Override
	public void declareOutputFields(OutputFieldsDeclarer declarer) {

	}
}
